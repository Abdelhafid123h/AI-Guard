import logging
from ..services.pii_detector_french import PIIDetectorFrench
from ..utils.token_manager import TokenManager
from ..services.llm_service import LLMService
from ..utils.config_loader import config_loader

class GuardService:
    def __init__(self, key: str = "ia_guards_secret_2025"):
        self.token_manager = TokenManager(key)
        self.llm_service = LLMService()
        self.pii_detector = PIIDetectorFrench()  # Nouveau d√©tecteur fran√ßais
        self.config_loader = config_loader  # Gestionnaire de configuration JSON

    def process(self, text: str, guard_type: str) -> dict:
        """Traite le texte pour d√©tecter, masquer, envoyer au LLM et restaurer les entit√©s sensibles."""
        logging.info(f"D√©but du traitement du texte (guard_type={guard_type})")
        all_entities = self.pii_detector.detect(text)
        logging.info(f"Entit√©s d√©tect√©es : {[(e['text'], e['type']) for e in all_entities]}")

        allowed_types = self.config_loader.get_guard_types(guard_type)
        if not allowed_types:
            logging.error(f"Guard type non support√© ou configuration manquante : {guard_type}")
            raise ValueError(f"Guard type non support√© ou configuration manquante : {guard_type}")

        entities = [e for e in all_entities if e['type'] in allowed_types]
        logging.info(f"Entit√©s filtr√©es pour {guard_type} : {[(e['text'], e['type']) for e in entities]}")
        logging.info(f"Types autoris√©s (depuis JSON) : {allowed_types}")

        masked_text, tokens = self.generate_tokens(text, entities)
        logging.info(f"Texte masqu√© g√©n√©r√© : {masked_text}")

        try:
            llm_response = self.llm_service.send_to_llm(masked_text)
            logging.info(f"R√©ponse LLM re√ßue : {llm_response}")
        except Exception as e:
            logging.error(f"Erreur lors de l'appel au LLM : {e}")
            llm_response = "[Erreur LLM]"

        unmasked_response = self.unmask(llm_response, tokens)
        logging.info(f"Texte d√©masqu√© g√©n√©r√© : {unmasked_response}")

        return {
            "original": text,
            "masked": masked_text,
            "llm_response": llm_response,
        "unmasked": unmasked_response
    }

    def generate_tokens(self, text: str, entities: list) -> tuple[str, dict]:
     """G√©n√®re des tokens pour les entit√©s d√©tect√©es et masque le texte."""
     tokens = {}
     masked_text = text
     print(f"Entit√©s re√ßues pour masquage : {entities}")  # Log pour d√©bogage
     
     # Trier les entit√©s par position (de la fin vers le d√©but pour √©viter les d√©calages)
     sorted_entities = sorted(entities, key=lambda x: x.get('start', 0), reverse=True)
     
     for entity in sorted_entities:
        if 'text' in entity and 'type' in entity:  # V√©rifiez que les cl√©s existent
            token = f"<{entity['type']}:{self.token_manager.generate_token(entity['text'])}>"
            tokens[token] = entity['text']
            
            # NOUVEAU: Utiliser la position exacte si disponible
            if 'start' in entity and 'end' in entity:
                # Remplacer par position exacte
                original_text = masked_text[entity['start']:entity['end']]
                print(f"üîÑ Remplacement positionnel: '{original_text}' ‚Üí '{token}'")
                masked_text = masked_text[:entity['start']] + token + masked_text[entity['end']:]
            else:
                # Fallback: remplacement par texte (m√©thode originale)
                print(f"üîÑ Remplacement textuel: '{entity['text']}' ‚Üí '{token}'")
                if entity['text'] in masked_text:
                    masked_text = masked_text.replace(entity['text'], token, 1)  # Une seule occurrence
                else:
                    print(f"‚ö†Ô∏è ATTENTION: Texte '{entity['text']}' non trouv√© pour remplacement")
        else:
            raise ValueError(f"Entit√© mal form√©e : {entity}")
     return masked_text, tokens

    def unmask(self, text: str, tokens: dict) -> str:
     """Restaure les entit√©s sensibles dans le texte."""
     for token, original in tokens.items():
        # Remplacez chaque token par sa valeur originale
        text = text.replace(token, original)
     return text