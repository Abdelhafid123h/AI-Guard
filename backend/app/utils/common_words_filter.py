"""
Filtre pour √©liminer les faux positifs des mod√®les NLP.
"""

# Mots fran√ßais communs qui ne sont jamais des entit√©s sensibles
COMMON_FRENCH_WORDS = {
    # Salutations et expressions courantes
    "salut", "bonjour", "bonsoir", "au revoir", "√† bient√¥t",
    
    # Pronoms et articles
    "je", "tu", "il", "elle", "nous", "vous", "ils", "elles",
    "le", "la", "les", "un", "une", "des", "du", "de", "d'",
    "ce", "cette", "ces", "mon", "ma", "mes", "ton", "ta", "tes",
    "son", "sa", "ses", "notre", "nos", "votre", "vos", "leur", "leurs",
    
    # Verbes auxiliaires et fr√©quents
    "√™tre", "avoir", "faire", "dire", "aller", "voir", "savoir",
    "pouvoir", "falloir", "vouloir", "venir", "prendre", "donner",
    "est", "sont", "ai", "as", "a", "avons", "avez", "ont",
    "suis", "es", "sommes", "√™tes",
    
    # Conjonctions et pr√©positions
    "et", "ou", "mais", "donc", "or", "ni", "car",
    "dans", "sur", "avec", "sans", "pour", "par", "contre",
    "sous", "vers", "chez", "depuis", "pendant", "avant", "apr√®s",
    
    # Expressions courantes
    "c'est", "ce sont", "il y a", "voil√†", "voici",
    "oui", "non", "peut-√™tre", "bien", "mal", "tr√®s", "plus", "moins",
    
    # Mots temporels
    "hier", "aujourd'hui", "demain", "maintenant", "toujours", "jamais",
    "souvent", "parfois", "quelquefois", "encore", "d√©j√†",
    
    # Nombres en lettres (petits nombres)
    "un", "deux", "trois", "quatre", "cinq", "six", "sept", "huit", "neuf", "dix"
}

# Patterns suspects qui ne devraient jamais √™tre des adresses/entreprises
SUSPICIOUS_PATTERNS = {
    "address": [
        r"^(salut|bonjour|bonsoir|hello|hi)$",
        r"^(oui|non|peut-√™tre|ok|d'accord)$",
        r"^(merci|s'il vous pla√Æt|excusez-moi)$"
    ],
    "company": [
        r"^(c'est|ce sont|il y a|voil√†|voici)$",
        r"^(je|tu|il|elle|nous|vous|ils|elles)$",
        r"^(le|la|les|un|une|des|du|de)$"
    ],
    "name": [
        r"^(le|la|les|un|une|des)$",
        r"^(et|ou|mais|donc|car)$"
    ]
}

import re

def is_common_word(text: str) -> bool:
    """V√©rifie si le texte est un mot commun fran√ßais."""
    return text.lower().strip() in COMMON_FRENCH_WORDS

def is_suspicious_entity(text: str, entity_type: str) -> bool:
    """V√©rifie si l'entit√© d√©tect√©e est suspecte selon son type."""
    if entity_type not in SUSPICIOUS_PATTERNS:
        return False
    
    text_clean = text.lower().strip()
    
    for pattern in SUSPICIOUS_PATTERNS[entity_type]:
        if re.match(pattern, text_clean, re.IGNORECASE):
            return True
    
    return False

def filter_false_positives(entities: list) -> list:
    """Filtre les faux positifs d'une liste d'entit√©s."""
    filtered = []
    
    for entity in entities:
        text = entity.get('text', '').strip()
        entity_type = entity.get('type', '')
        
        # Ignorer les entit√©s vides ou trop courtes
        if len(text) < 2:
            continue
            
        # Ignorer les mots communs
        if is_common_word(text):
            print(f"üö´ Filtr√© mot commun: '{text}' ({entity_type})")
            continue
            
        # Ignorer les patterns suspects
        if is_suspicious_entity(text, entity_type):
            print(f"üö´ Filtr√© pattern suspect: '{text}' ({entity_type})")
            continue
            
        # Garder l'entit√©
        filtered.append(entity)
    
    return filtered
